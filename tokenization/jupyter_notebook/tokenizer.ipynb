{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceda2669-7577-4075-9bad-dff9085d82d6",
   "metadata": {},
   "source": [
    "# Tokenizer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b6c14f4-e0f2-4823-8d93-ed3422602714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string length: 38342\n",
      "Encoded string length: 38425\n"
     ]
    }
   ],
   "source": [
    "text = \"Introduction Artificial intelligence, or AI, is concerned with building systems that simulate intelligent behavior. It encompasses a wide range of approaches, including those based on logic, search, and probabilistic reasoning. Machine learning is a subset of AI that learns to make decisions by fitting mathematical models to observed data. This area has seen explosive growth and is now (incorrectly) almost synonymous with the term AI. A deep neural network is a type of machine learning model, and when it is fitted to data, this is referred to as deep learning. At the time of writing, deep networks are the most powerful and practical machine learning models and are often encountered in day-to-day life. It is commonplace to translate text from another language using a natural language processing algorithm, to search the internet for images of a particular object using a computer vision system, or to converse with a digital assistant via a speech recognition interface. All of these applications are powered by deep learning. As the title suggests, this book aims to help a reader new to this field understand the principles behind deep learning. The book is neither terribly theoretical (there are no proofs) nor extremely practical (there is almost no code). The goal is to explain the underlying ideas; after consuming this volume, the reader will be able to apply deep learning to novel situations where there is no existing recipe for success. Machine learning methods can coarsely be divided into three areas: supervised, unsu- pervised, and reinforcement learning. At the time of writing, the cutting-edge methods in all three areas rely on deep learning (figure 1.1). This introductory chapter describes these three areas at a high level, and this taxonomy is also loosely reflected in the book’s organization. Whether we like it or not, deep learning is poised to change our world, and this change will not all be positive. Hence, this chapter also contains brief primer on AI ethics. We conclude with advice on how to make the most of this book. 1.1 Supervised learning Supervised learning models define a mapping from input data to an output prediction. In the following sections, we discuss the inputs, the outputs, the model itself, and what is meant by “learning” a model. Draft: please send errata to udlbookmail@gmail.com. 2 1 Introduction Figure 1.1 Machine learning is an area of artificial intelligence that fits math- ematical models to observed data. It can coarsely be divided into supervised learning, unsupervised learning, and re- inforcement learning. Deep neural net- works contribute to each of these areas. 1.1.1 Regression and classification problems Figure 1.2 depicts several regression and classification problems. In each case, there is a meaningful real-world input (a sentence, a sound file, an image, etc.), and this is encoded as a vector of numbers. This vector forms the model input. The model maps the input to an output vector which is then “translated” back to a meaningful real-world prediction. For now, we focus on the inputs and outputs and treat the model as a black box that ingests a vector of numbers and returns another vector of numbers. The model in figure 1.2a predicts the price of a house based on input characteristics such as the square footage and the number of bedrooms. This is a regression problem because the model returns a continuous number (rather than a category assignment). In contrast, the model in 1.2b takes the chemical structure of a molecule as an input and predicts both the melting and boiling points. This is a multivariate regression problem since it predicts more than one number. The model in figure 1.2c receives a text string containing a restaurant review as input and predicts whether the review is positive or negative. This is a binary classification problem because the model attempts to assign the input to one of two categories. The output vector contains the probabilities that the input belongs to each category. Fig- ures 1.2d and 1.2e depict multiclass classification problems. Here, the model assigns the input to one of N >2 categories. In the first case, the input is an audio file, and the model predicts which genre of music it contains. In the second case, the input is an image, and the model predicts which object it contains. In each case, the model returns a vector of size N that contains the probabilities of the N categories. 1.1.2 Inputs The input data in figure 1.2 varies widely. In the house pricing example, the input is a fixed-length vector containing values that characterize the property. This is an example of tabular data because it has no internal structure; if we change the order of the inputs and build a new model, then we expect the model prediction to remain the same. Conversely, the input in the restaurant review example is a body of text. This may be of variable length depending on the number of words in the review, and here input This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.1 Supervised learning 3 Figure 1.2 Regression and classification problems. a) This regression model takes a vector of numbers that characterize a property and predicts its price. b) This multivariate regression model takes the structure of a chemical molecule and predicts its melting and boiling points. c) This binary classification model takes a restaurant review and classifies it as either positive or negative. d) This multiclass classification problem assigns a snippet of audio to one of N genres. e) A second multiclass classification problem in which the model classifies an image according to which of N possible objects it might contain. Draft: please send errata to udlbookmail@gmail.com. 4 1 Introduction Figure 1.3 Machine learning model. The model represents a family of relationships that relate the input (age of child) to the output (height of child). The particular relationship is chosen using training data, which consists of input/output pairs (orange points). When we train the model, we search through the possible re- lationships for one that describes the data well. Here, the trained model is the cyan curve and can be used to compute the height for any age. order is important; my wife ate the chicken is not the same as the chicken ate my wife. The text must be encoded into numerical form before passing it to the model. Here, we use a fixed vocabulary of size 10,000 and simply concatenate the word indices. For the music classification example, the input vector might be of fixed size (perhaps a 10-second clip) but is very high-dimensional. Digital audio is usually sampled at 44.1 kHz and represented by 16-bit integers, so a ten-second clip consists of 441,000 integers. Clearly, supervised learning models will have to be able to process sizeable inputs. The input in the image classification example (which consists of the concatenated RGB values at every pixel) is also enormous. Moreover, its structure is naturally two-dimensional; two pixels above and below one another are closely related, even if they are not adjacent in the input vector. Finally, consider the input for the model that predicts the melting and boiling points of the molecule. A molecule may contain varying numbers of atoms that can be connected in different ways. In this case, the model must ingest both the geometric structure of the molecule and the constituent atoms to the model. 1.1.3 Machine learning models Until now, we have treated the machine learning model as a black box that takes an input vector and returns an output vector. But what exactly is in this black box? Consider a model to predict the height of a child from their age (figure 1.3). The machine learning This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.1 Supervised learning 5 model is a mathematical equation that describes how the average height varies as a function of age (cyan curve in figure 1.3). When we run the age through this equation, it returns the height. For example, if the age is 10 years, then we predict that the height will be 139 cm. More precisely, the model represents a family of equations mapping the input to the output (i.e., a family of different cyan curves). The particular equation (curve) is chosen using training data (examples of input/output pairs). In figure 1.3, these pairs are represented by the orange points, and we can see that the model (cyan line) describes these data reasonably. When we talk about training or fitting a model, we mean that we search through the family of possible equations (possible cyan curves) relating input to output to find the one that describes the training data most accurately. It follows that the models in figure 1.2 require labeled input/output pairs for training. For example, the music classification model would require a large number of audio clips where a human expert had identified the genre of each. These input/output pairs take the role of a teacher or supervisor for the training process, and this gives rise to the term supervised learning. 1.1.4 Deep neural networks This book concerns deep neural networks, which are a particularly useful type of machine learning model. They are equations that can represent an extremely broad family of relationships between input and output, and where it is particularly easy to search through this family to find the relationship that describes the training data. Deep neural networks can process inputs that are very large, of variable length, and contain various kinds of internal structures. They can output single real numbers (regression), multiple numbers (multivariate regression), or probabilities over two or more classes (binary and multiclass classification, respectively). As we shall see in the next section, their outputs may also be very large, of variable length, and contain internal structure. It is probably hard to imagine equations with these properties, and the reader should endeavor to suspend disbelief for now. 1.1.5 Structured outputs Figure 1.4a depicts a multivariate binary classification model for semantic segmentation. Here, every pixel of an input image is assigned a binary label that indicates whether it belongs to a cow or the background. Figure 1.4b shows a multivariate regression model where the input is an image of a street scene and the output is the depth at each pixel. In both cases, the output is high-dimensional and structured. However, this structure is closely tied to the input, and this can be exploited; if a pixel is labeled as “cow,” then a neighbor with a similar RGB value probably has the same label. Figures 1.4c–e depict three models where the output has a complex structure that is not so closely tied to the input. Figure 1.4c shows a model where the input is an audio file and the output is the transcribed words from that file. Figure 1.4d is a translation Draft: please send errata to udlbookmail@gmail.com. 6 1 Introduction Figure 1.4 Supervised learning tasks with structured outputs. a) This semantic segmentation model maps an RGB image to a binary image indicating whether each pixel belongs to the background or a cow (adapted from Noh et al., 2015). b) This monocular depth estimation model maps an RGB image to an output image where each pixel represents the depth (adapted from Cordts et al., 2016). c) This audio transcription model maps an audio sample to a transcription of the spoken words in the audio. d) This translation model maps an English text string to its French translation. e) This image synthesis model maps a caption to an image (example from https://openai.com/dall-e-2/). In each case, the output has a complex internal structure or grammar. In some cases, many outputs are compatible with the input. This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.2 Unsupervised learning 7 model in which the input is a body of text in English, and the output contains the French translation. Figure 1.4e depicts a very challenging task in which the input is descriptive text, and the model must produce an image that matches this description. In principle, the latter three tasks can be tackled in the standard supervised learning framework, but they are more diﬀicult for two reasons. First, the output may genuinely be ambiguous; there are multiple valid translations from an English sentence to a French one and multiple images that are compatible with any caption. Second, the output contains considerable structure; not all strings of words make valid English and French sentences, and not all collections of RGB values make plausible images. In addition to learning the mapping, we also have to respect the “grammar” of the output. Fortunately, this “grammar” can be learned without the need for output labels. For example, we can learn how to form valid English sentences by learning the statistics of a large corpus of text data. This provides a connection with the next section of the book, which considers unsupervised learning models. 1.2 Unsupervised learning Constructing a model from input data without corresponding output labels is termed unsupervised learning; the absence of output labels means there can be no “supervision.” Rather than learning a mapping from input to output, the goal is to describe or under- stand the structure of the data. As was the case for supervised learning, the data may have very different characteristics; it may be discrete or continuous, low-dimensional or high-dimensional, and of constant or variable length. 1.2.1 Generative models This book focuses on generative unsupervised models, which learn to synthesize new data examples that are statistically indistinguishable from the training data. Some generative models explicitly describe the probability distribution over the input data and here new examples are generated by sampling from this distribution. Others merely learn a mechanism to generate new examples without explicitly describing their distribution. State-of-the-art generative models can synthesize examples that are extremely plau- sible but distinct from the training examples. They have been particularly successful at generating images (figure 1.5) and text (figure 1.6). They can also synthesize data under the constraint that some outputs are predetermined (termed conditional genera- tion). Examples include image inpainting (figure 1.7) and text completion (figure 1.8). Indeed, modern generative models for text are so powerful that they can appear intel- ligent. Given a body of text followed by a question, the model can often “fill in” the missing answer by generating the most likely completion of the document. However, in reality, the model only knows about the statistics of language and does not understand the significance of its answers. Draft: please send errata to udlbookmail@gmail.com. 8 1 Introduction Figure 1.5 Generative models for images. Left: two images were generated from a model trained on pictures of cats. These are not real cats, but samples from a probability model. Right: two images generated from a model trained on images of buildings. Adapted from Karras et al. (2020b). The moon had risen by the time I reached the edge of the forest, and the light that filtered through the trees was silver and cold. I shivered, though I was not cold, and quickened my pace. I had never been so far from the village before, and I was not sure what to expect. I had been walking for hours, and I was tired and hungry. I had left in such a hurry that I had not thought to pack any food, and I had not thought to bring a weapon. I was unarmed and alone in a strange place, and I did not know what I was doing. I had been walking for so long that I had lost all sense of time, and I had no idea how far I had come. I only knew that I had to keep going. I had to find her. I was getting close. I could feel it. She was nearby, and she was in trouble. I had to find her and help her, before it was too late. Figure 1.6 Short story synthesized from a generative model of text data. The model describes a probability distribution that assigns a probability to every output string. Sampling from the model creates strings that follow the statistics of the training data (here, short stories) but have never been seen before. Figure 1.7 Inpainting. In the original image (left), the boy is obscured by metal cables. These undesirable regions (center) are removed and the generative model synthesizes a new image (right) under the constraint that the remaining pixels must stay the same. Adapted from Saharia et al. (2022a). This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.2 Unsupervised learning 9 I was a little nervous before my first lecture at the University of Bath. It seemed like there were hundreds of students and they looked intimidating. I stepped up to the lectern and was about to speak when something bizarre happened. Suddenly, the room was filled with a deafening noise, like a giant roar. It was so loud that I couldn’t hear anything else and I had to cover my ears. I could see the students looking around, con- fused and frightened. Then, as quickly as it had started, the noise stopped and the room was silent again. I stood there for a few moments, trying to make sense of what had just happened. Then I realized that the students were all staring at me, waiting for me to say something. I tried to think of something witty or clever to say, but my mind was blank. So I just said, “Well, that was strange,’ and then I started my lecture. Figure 1.8 Conditional text synthesis. Given an initial body of text (in black), generative models of text can continue the string plausibly by synthesizing the “missing” remaining part of the string. Generated by GPT3 (Brown et al., 2020). Figure 1.9 Variation of the human face. The human face contains roughly 42 muscles, so it’s possible to describe most of the variation in images of the same person in the same lighting with just 42 numbers. In general, datasets of images, music, and text can be described by a relatively small number of underlying variables although it is typically more diﬀicult to tie these to particular physical mechanisms. Images from Dynamic FACES database (Holland et al., 2019). 1.2.2 Latent variables Some (but not all) generative models exploit the observation that data can be lower dimensional than the raw number of observed variables suggests. For example, the num- ber of valid and meaningful English sentences is considerably smaller than the number of strings created by drawing words at random. Similarly, real-world images are a tiny subset of the images that can be created by drawing random RGB values for every pixel. This is because images are generated by physical processes (see figure 1.9). This leads to the idea that we can describe each data example using a smaller number of underlying latent variables. Here, the role of deep learning is to describe the mapping between these latent variables and the data. The latent variables typically have a simple Draft: please send errata to udlbookmail@gmail.com. 10 1 Introduction Figure 1.10 Latent variables. Many generative models use a deep learning model to describe the relationship between a low-dimensional “latent” variable and the observed high-dimensional data. The latent variables have a simple probability distribution by design. Hence, new examples can be generated by sampling from the simple distribution over the latent variables and then using the deep learning model to map the sample to the observed data space. Figure 1.11 Image interpolation. In each row the left and right images are real and the three images in between represent a sequence of interpolations created by a generative model. The generative models that underpin these interpolations have learned that all images can be created by a set of underlying latent variables. By finding these variables for the two real images, interpolating their values, and then using these intermediate variables to create new images, we can generate intermediate results that are both visually plausible and mix the characteristics of the two original images. Top row adapted from Sauer et al. (2022). Bottom row adapted from Ramesh et al. (2022). This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.3 Reinforcement learning 11 Figure 1.12 Multiple images generated from the caption “A teddy bear on a skateboard in Times Square.” Generated by DALL·E-2 (Ramesh et al., 2022). probability distribution by design. By sampling from this distribution and passing the result through the deep learning model, we can create new samples (figure 1.10). These models lead to new methods for manipulating real data. For example, consider finding the latent variables that underpin two real examples. We can interpolate between these examples by interpolating between their latent representations and mapping the intermediate positions back into the data space (figure 1.11). 1.2.3 Connecting supervised and unsupervised learning Generative models with latent variables can also benefit supervised learning models where the outputs have structure (figure 1.4). For example, consider learning to predict the images corresponding to a caption. Rather than directly map the text input to an image, we can learn a relation between latent variables that explain the text and the latent variables that explain the image. This has three advantages. First, we may need fewer text/image pairs to learn this mapping now that the inputs and outputs are lower dimensional. Second, we are more likely to generate a plausible-looking image; any sensible values of the latent variables should produce something that looks like a plausible example. Third, if we introduce randomness to either the mapping between the two sets of latent variables or the mapping from the latent variables to the image, then we can generate multiple images that are all described well by the caption (figure 1.12). 1.3 Reinforcement learning The final area of machine learning is reinforcement learning. This paradigm introduces the idea of an agent which lives in a world and can perform certain actions at each time step. The actions change the state of the system but not necessarily in a deterministic way. Taking an action can also produce rewards, and the goal of reinforcement learning Draft: please send errata to udlbookmail@gmail.com. 12 1 Introduction is for the agent to learn to choose actions that lead to high rewards on average. One complication is that the reward may occur some time after the action is taken, so associating a reward with an action is not straightforward. This is known as the temporal credit assignment problem. As the agent learns, it must trade off exploration and exploitation of what it already knows; perhaps the agent has already learned how to receive modest rewards; should it follow this strategy (exploit what it knows), or should it try different actions to see if it can improve (explore other opportunities)? 1.3.1 Two examples Consider teaching a humanoid robot to locomote. The robot can perform a limited number of actions at a given time (moving various joints), and these change the state of the world (its pose). We might reward the robot for reaching checkpoints in an obstacle course. To reach each checkpoint, it must perform many actions, and it’s unclear which ones contributed to the reward when it is received and which were irrelevant. This is an example of the temporal credit assignment problem. A second example is learning to play chess. Again, the agent has a set of valid actions (chess moves) at any given time. However, these actions change the state of the system in a non-deterministic way; for any choice of action, the opposing player might respond with many different moves. Here, we might set up a reward structure based on capturing pieces or just have a single reward at the end of the game for winning. In the latter case, the temporal credit assignment problem is extreme; the system must learn which of the many moves it made were instrumental to success or failure. The exploration-exploitation trade-off is also apparent in these two examples. The robot may have discovered that it can make progress by lying on its side and pushing with one leg. This strategy will move the robot and yields rewards, but much more slowly than the optimal solution: to balance on its legs and walk. So, it faces a choice between exploiting what it already knows (how to slide along the floor awkwardly) and exploring the space of actions (which might result in much faster locomotion). Similarly, in the chess example, the agent may learn a reasonable sequence of opening moves. Should it exploit this knowledge or explore different opening sequences? It is perhaps not obvious how deep learning fits into the reinforcement learning frame- work. There are several possible approaches, but one technique is to use deep networks to build a mapping from the observed world state to an action. This is known as a policy network. In the robot example, the policy network would learn a mapping from its sensor measurements to joint movements. In the chess example, the network would learn a mapping from the current state of the board to the choice of move (figure 1.13). 1.4 Ethics It would be irresponsible to write this book without discussing the ethical implications of artificial intelligence. This potent technology will change the world to at least the This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.4 Ethics 13 Figure 1.13 Policy networks for reinforcement learning. One way to incorporate deep neural networks into reinforcement learning is to use them to define a map- ping from the state (here position on chessboard) to the actions (possible moves). This mapping is known as a policy. Adapted from Pablok (2017). same extent as electricity, the internal combustion engine, the transistor, or the internet. The potential benefits in healthcare, design, entertainment, transport, education, and almost every area of commerce are enormous. However, scientists and engineers are often unrealistically optimistic about the outcomes of their work, and the potential for harm is just as great. The following paragraphs highlight five concerns. Bias and fairness: If we train a system to predict salary levels for individuals based on historical data, then this system will reproduce historical biases; for example, it will probably predict that women should be paid less than men. Several such cases have already become international news stories: an AI system for super-resolving face images made non-white people look more white; a system for generating images produced only pictures of men when asked to synthesize pictures of lawyers. Careless application of algorithmic decision-making using AI has the potential to entrench or aggravate existing biases. See Binns (2018) for further discussion. Explainability: Deep learning systems make decisions, but we do not usually know exactly how or based on what information. They may contain billions of parameters, and there is no way we can understand how they work based on examination. This has led to the sub-field of explainable AI. One moderately successful area is producing local explanations; we cannot explain the entire system, but we can produce an interpretable description of why a particular decision was made. However, it remains unknown whether it is possible to build complex decision-making systems that are fully transparent to their users or even their creators. See Grennan et al. (2022) for further information. Weaponizing AI: All significant technologies have been applied directly or indirectly toward war. Sadly, violent conflict seems to be an inevitable feature of human behavior. AI is arguably the most powerful technology ever built and will doubtless be deployed extensively in a military context. Indeed, this is already happening (Heikkilä, 2022). Draft: please send errata to udlbookmail@gmail.com. 14 1 Introduction Concentrating power: It is not from a benevolent interest in improving the lot of the human race that the world’s most powerful companies are investing heavily in artifi- cial intelligence. They know that these technologies will allow them to reap enormous profits. Like any advanced technology, deep learning is likely to concentrate power in the hands of the few organizations that control it. Automating jobs that are currently done by humans will change the economic environment and disproportionately affect the livelihoods of lower-paid workers with fewer skills. Optimists argue similar disruptions happened during the industrial revolution and resulted in shorter working hours. The truth is that we simply do not know what effects the large-scale adoption of AI will have on society (see David, 2015). Existential risk: The major existential risks to the human race all result from tech- nology. Climate change has been driven by industrialization. Nuclear weapons derive from the study of physics. Pandemics are more probable and spread faster because in- novations in transport, agriculture, and construction have allowed a larger, denser, and more interconnected population. Artificial intelligence brings new existential risks. We should be very cautious about building systems that are more capable and extensible than human beings. In the most optimistic case, it will put vast power in the hands of the owners. In the most pessimistic case, we will be unable to control it or even understand its motives (see Tegmark, 2018). This list is far from exhaustive. AI could also enable surveillance, disinformation, violations of privacy, fraud, and manipulation of financial markets, and the energy re- quired to train AI systems contributes to climate change. Moreover, these concerns are not speculative; there are already many examples of ethically dubious applications of AI (consult Dao, 2021, for a partial list). In addition, the recent history of the inter- net has shown how new technology can cause harm in unexpected ways. The online community of the eighties and early nineties could hardly have predicted the prolifera- tion of fake news, spam, online harassment, fraud, cyberbullying, incel culture, political manipulation, doxxing, online radicalization, and revenge porn. Everyone studying or researching (or writing books about) AI should contemplate to what degree scientists are accountable for the uses of their technology. We should consider that capitalism primarily drives the development of AI and that legal advances and deployment for social good are likely to lag significantly behind. We should reflect on whether it’s possible, as scientists and engineers, to control progress in this field and to reduce the potential for harm. We should consider what kind of organizations we are prepared to work for. How serious are they in their commitment to reducing the potential harms of AI? Are they simply “ethics-washing” to reduce reputational risk, or do they actually implement mechanisms to halt ethically suspect projects? All readers are encouraged to investigate these issues further. The online course at https://ethics-of-ai.mooc.fi/ is a useful introductory resource. If you are a professor teaching from this book, you are encouraged to raise these issues with your students. If you are a student taking a course where this is not done, then lobby your professor to make this happen. If you are deploying or researching AI in a corporate environment, you are encouraged to scrutinize your employer’s values and to help change them (or leave) if they are wanting. This work is subject to a Creative Commons CC-BY-NC-ND license. (C) MIT Press. 1.5 Structure of book 15 1.5 Structure of book The structure of the book follows the structure of this introduction. Chapters 2–9 walk through the supervised learning pipeline. We describe shallow and deep neural networks and discuss how to train them and measure and improve their performance. Chap- ters 10–13 describe common architectural variations of deep neural networks, including convolutional networks, residual connections, and transformers. These architectures are used across supervised, unsupervised, and reinforcement learning. Chapters 14–18 tackle unsupervised learning using deep neural networks. We devote a chapter each to four modern deep generative models: generative adversarial networks, variational autoencoders, normalizing flows, and diffusion models. Chapter 19 is a brief introduction to deep reinforcement learning. This is a topic that easily justifies its own book, so the treatment is necessarily superficial. However, this treatment is intended to be a good starting point for readers unfamiliar with this area. Despite the title of this book, some aspects of deep learning remain poorly under- stood. Chapter 20 poses some fundamental questions. Why are deep networks so easy to train? Why do they generalize so well? Why do they need so many parameters? Do they need to be deep? Along the way, we explore unexpected phenomena such as the structure of the loss function, double descent, grokking, and lottery tickets. The book concludes with chapter 21, which discusses ethics and deep learning. 1.6 Other books This book is self-contained but is limited to coverage of deep learning. It is intended to be the spiritual successor to Deep Learning (Goodfellow et al., 2016) which is a fantastic resource but does not cover recent advances. For a broader look at machine learning, the most up-to-date and encyclopedic resource is Probabilistic Machine Learning (Murphy, 2022, 2023). However, Pattern Recognition and Machine Learning (Bishop, 2006) is still an excellent and relevant book. If you enjoy this book, then my previous volume, Computer Vision: Models, Learning, and Inference (Prince, 2012), is still worth reading. Some parts have dated badly, but it contains a thorough introduction to probability, including Bayesian methods, and good introductory coverage of latent variable models, geometry for computer vision, Gaussian processes, and graphical models. It uses identical notation to this book and can be found online. A detailed treatment of graphical models can be found in Probabilistic Graphical Models: Principles and Techniques (Koller & Friedman, 2009), and Gaussian processes are covered by Gaussian Processes for Machine Learning (Williams & Rasmussen, 2006). For background mathematics, consult Mathematics for Machine Learning (Deisen- roth et al., 2020). For a more coding-oriented approach, consult Dive into Deep Learning (Zhang et al., 2023). The best overview for computer vision is Szeliski (2022), and there is also the impending book Foundations of Computer Vision (Torralba et al., 2024). A good starting point to learn about graph neural networks is Graph Representation Learning (Hamilton, 2020). The definitive work on reinforcement learning is Reinforce- Draft: please send errata to udlbookmail@gmail.com. 16 1 Introduction ment Learning: An Introduction (Sutton & Barto, 2018). A good initial resource is Foundations of Deep Reinforcement Learning (Graesser & Keng, 2019). 1.7 Appendix A Notation Notebook 1.1 Background mathematics How to read this book Most remaining chapters in this book contain a main body of text, a notes section, and a set of problems. The main body of the text is intended to be self-contained and can be read without recourse to the other parts of the chapter. As much as possible, background mathematics is incorporated into the main body of the text. However, for larger topics that would be a distraction to the main thread of the argument, the background material is appendicized, and a reference is provided in the margin. Most notation in this book is standard. However, some conventions are less widely used, and the reader is encouraged to consult appendix A before proceeding. The main body of text includes many novel illustrations and visualizations of deep learning models and results. I’ve worked hard to provide new explanations of existing ideas rather than merely curate the work of others. Deep learning is a new field, and sometimes phenomena are poorly understood. I try to make it clear where this is the case and when my explanations should be treated with caution. References are included in the main body of the chapter only where results are de- picted. Instead, they can be found in the notes section at the end of the chapter. I do not generally respect historical precedent in the main text; if an ancestor of a current technique is no longer useful, then I will not mention it. However, the historical develop- ment of the field is described in the notes section, and hopefully, credit is fairly assigned. The notes are organized into paragraphs and provide pointers for further reading. They should help the reader orient themselves within the sub-area and understand how it re- lates to other parts of machine learning. The notes are less self-contained than the main text. Depending on your level of background knowledge and interest, you may find these sections more or less useful. Each chapter has a number of associated problems. They are referenced in the margin of the main text at the point that they should be attempted. As George Pólya noted, “Mathematics, you see, is not a spectator sport.” He was correct, and I highly recommend that you attempt the problems as you go. In some cases, they provide insights that will help you understand the main text. Problems for which the answers are provided on the associated website are indicated with an asterisk. Additionally, Python notebooks that will help you understand the ideas in this book are also available via the website, and these are also referenced in the margins of the text. Indeed, if you are feeling rusty, it might be worth working through the notebook on background mathematics right now. Unfortunately, the pace of research in AI makes it inevitable that this book will be a constant work in progress. If there are parts you find hard to understand, notable omis- sions, or sections that seem extraneous, please get in touch via the associated website. Together, we can make the next edition better.\"\n",
    "tokens = list(text.encode(\"utf-8\"))\n",
    "\n",
    "print(\"Original string length: \" + str(len(text))) \n",
    "print(\"Encoded string length: \" + str(len(tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1afa45b7-cba4-43a2-a608-eb009075e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCommonPair(lst):\n",
    "    seen = {}\n",
    "    for i in range(0, len(lst) - 1):\n",
    "        string = tuple(lst[i:i+2])\n",
    "        if string in seen:\n",
    "            seen[string] += 1\n",
    "        else:\n",
    "            seen[string] = 1\n",
    "    return seen\n",
    "\n",
    "stats = getCommonPair(tokens)\n",
    "# print(stats)\n",
    "print(sorted(((v,k) for k,v in stats.items()), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d197881-5790-48ba-bfa5-16ca0bb62763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  37288\n"
     ]
    }
   ],
   "source": [
    "def merge(lst, pair, new_id):\n",
    "    new_lst = []\n",
    "    i = 0\n",
    "    while i < len(lst):\n",
    "        if i < len(lst)-1 and lst[i] == pair[0] and lst[i+1] == pair[1]:\n",
    "            new_lst.append(new_id)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_lst.append(lst[i])\n",
    "            i += 1\n",
    "    return new_lst\n",
    "\n",
    "# print(merge([5, 6, 6, 7, 9, 1], (6, 7), 99))\n",
    "\n",
    "top_pair = max(stats, key=stats.get)\n",
    "tokens2 = merge(tokens, top_pair, 256)\n",
    "print(\"length: \", len(tokens2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5b9b6d6-d719-4a1f-8a43-3f56559bee1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n",
      "merged (101, 32) into a new token 256\n",
      "merged (32, 116) into a new token 257\n",
      "merged (105, 110) into a new token 258\n",
      "merged (115, 32) into a new token 259\n",
      "merged (257, 104) into a new token 260\n",
      "merged (116, 32) into a new token 261\n",
      "merged (101, 114) into a new token 262\n",
      "merged (97, 110) into a new token 263\n",
      "merged (111, 110) into a new token 264\n",
      "merged (100, 32) into a new token 265\n",
      "merged (97, 114) into a new token 266\n",
      "merged (101, 110) into a new token 267\n",
      "merged (46, 32) into a new token 268\n",
      "merged (97, 116) into a new token 269\n",
      "merged (260, 256) into a new token 270\n",
      "merged (111, 114) into a new token 271\n",
      "merged (114, 101) into a new token 272\n",
      "merged (258, 103) into a new token 273\n",
      "merged (121, 32) into a new token 274\n",
      "merged (44, 32) into a new token 275\n",
      "merged (108, 101) into a new token 276\n",
      "merged (97, 108) into a new token 277\n",
      "merged (105, 264) into a new token 278\n",
      "merged (100, 101) into a new token 279\n",
      "merged (111, 32) into a new token 280\n",
      "merged (105, 99) into a new token 281\n",
      "merged (111, 102) into a new token 282\n",
      "merged (105, 259) into a new token 283\n",
      "merged (97, 32) into a new token 284\n",
      "merged (115, 116) into a new token 285\n",
      "merged (273, 32) into a new token 286\n",
      "merged (114, 111) into a new token 287\n",
      "merged (116, 104) into a new token 288\n",
      "merged (111, 117) into a new token 289\n",
      "merged (115, 101) into a new token 290\n",
      "merged (109, 97) into a new token 291\n",
      "merged (257, 280) into a new token 292\n",
      "merged (109, 111) into a new token 293\n",
      "merged (99, 116) into a new token 294\n",
      "merged (99, 104) into a new token 295\n",
      "merged (263, 265) into a new token 296\n",
      "merged (282, 32) into a new token 297\n",
      "merged (101, 115) into a new token 298\n",
      "merged (101, 120) into a new token 299\n",
      "merged (263, 32) into a new token 300\n",
      "merged (105, 103) into a new token 301\n",
      "merged (112, 117) into a new token 302\n",
      "merged (271, 32) into a new token 303\n",
      "merged (105, 108) into a new token 304\n",
      "merged (105, 116) into a new token 305\n",
      "merged (117, 114) into a new token 306\n",
      "merged (84, 104) into a new token 307\n",
      "merged (266, 110) into a new token 308\n",
      "merged (108, 32) into a new token 309\n",
      "merged (277, 32) into a new token 310\n",
      "merged (293, 279) into a new token 311\n",
      "merged (101, 265) into a new token 312\n",
      "merged (276, 308) into a new token 313\n",
      "merged (97, 261) into a new token 314\n",
      "merged (97, 98) into a new token 315\n",
      "merged (269, 278) into a new token 316\n",
      "merged (99, 264) into a new token 317\n",
      "merged (97, 115) into a new token 318\n",
      "merged (111, 119) into a new token 319\n",
      "merged (262, 32) into a new token 320\n",
      "merged (268, 307) into a new token 321\n",
      "merged (111, 109) into a new token 322\n",
      "merged (105, 115) into a new token 323\n",
      "merged (108, 256) into a new token 324\n",
      "merged (97, 109) into a new token 325\n",
      "merged (115, 105) into a new token 326\n",
      "merged (101, 108) into a new token 327\n",
      "merged (49, 46) into a new token 328\n",
      "merged (101, 259) into a new token 329\n",
      "merged (258, 116) into a new token 330\n",
      "merged (267, 261) into a new token 331\n",
      "merged (110, 101) into a new token 332\n",
      "merged (112, 287) into a new token 333\n",
      "merged (98, 111) into a new token 334\n",
      "merged (266, 256) into a new token 335\n",
      "merged (115, 117) into a new token 336\n",
      "merged (267, 116) into a new token 337\n",
      "merged (104, 97) into a new token 338\n",
      "merged (268, 73) into a new token 339\n",
      "merged (105, 118) into a new token 340\n",
      "merged (114, 97) into a new token 341\n",
      "merged (119, 104) into a new token 342\n",
      "merged (306, 256) into a new token 343\n",
      "merged (101, 109) into a new token 344\n",
      "merged (260, 314) into a new token 345\n",
      "merged (119, 271) into a new token 346\n",
      "merged (112, 108) into a new token 347\n",
      "merged (117, 110) into a new token 348\n",
      "merged (263, 100) into a new token 349\n",
      "merged (278, 32) into a new token 350\n",
      "merged (101, 100) into a new token 351\n",
      "merged (110, 111) into a new token 352\n",
      "merged (256, 288) into a new token 353\n",
      "merged (302, 261) into a new token 354\n",
      "merged (118, 105) into a new token 355\n",
      "merged (267, 32) into a new token 356\n",
      "merged (258, 32) into a new token 357\n",
      "merged (112, 111) into a new token 358\n",
      "merged (311, 108) into a new token 359\n",
      "merged (291, 103) into a new token 360\n",
      "merged (112, 32) into a new token 361\n",
      "merged (112, 276) into a new token 362\n",
      "merged (100, 105) into a new token 363\n",
      "merged (107, 32) into a new token 364\n",
      "merged (117, 115) into a new token 365\n",
      "merged (105, 360) into a new token 366\n",
      "merged (98, 256) into a new token 367\n",
      "merged (114, 105) into a new token 368\n",
      "merged (108, 274) into a new token 369\n",
      "merged (313, 286) into a new token 370\n",
      "merged (289, 116) into a new token 371\n",
      "merged (44, 270) into a new token 372\n",
      "merged (99, 300) into a new token 373\n",
      "merged (102, 271) into a new token 374\n",
      "merged (272, 115) into a new token 375\n",
      "merged (302, 116) into a new token 376\n",
      "merged (112, 262) into a new token 377\n",
      "merged (282, 270) into a new token 378\n",
      "merged (118, 262) into a new token 379\n",
      "merged (117, 294) into a new token 380\n",
      "merged (105, 261) into a new token 381\n",
      "merged (97, 259) into a new token 382\n",
      "merged (112, 116) into a new token 383\n",
      "merged (311, 309) into a new token 384\n",
      "merged (266, 105) into a new token 385\n",
      "merged (117, 108) into a new token 386\n",
      "merged (115, 268) into a new token 387\n",
      "merged (41, 32) into a new token 388\n",
      "merged (109, 32) into a new token 389\n",
      "merged (102, 287) into a new token 390\n",
      "merged (334, 111) into a new token 391\n",
      "merged (97, 100) into a new token 392\n",
      "merged (226, 128) into a new token 393\n",
      "merged (275, 296) into a new token 394\n",
      "merged (102, 303) into a new token 395\n",
      "merged (301, 343) into a new token 396\n",
      "merged (396, 328) into a new token 397\n",
      "merged (119, 256) into a new token 398\n",
      "merged (101, 361) into a new token 399\n",
      "merged (260, 283) into a new token 400\n",
      "merged (97, 99) into a new token 401\n",
      "merged (267, 262) into a new token 402\n",
      "merged (98, 101) into a new token 403\n",
      "merged (100, 269) into a new token 404\n",
      "merged (117, 109) into a new token 405\n",
      "merged (285, 114) into a new token 406\n",
      "merged (50, 48) into a new token 407\n",
      "merged (98, 117) into a new token 408\n",
      "merged (321, 256) into a new token 409\n",
      "merged (101, 294) into a new token 410\n",
      "merged (119, 105) into a new token 411\n",
      "merged (99, 322) into a new token 412\n",
      "merged (97, 295) into a new token 413\n",
      "merged (99, 108) into a new token 414\n",
      "merged (115, 99) into a new token 415\n",
      "merged (301, 104) into a new token 416\n",
      "merged (299, 325) into a new token 417\n",
      "merged (105, 285) into a new token 418\n",
      "merged (317, 116) into a new token 419\n",
      "merged (73, 32) into a new token 420\n",
      "merged (118, 385) into a new token 421\n",
      "merged (269, 256) into a new token 422\n",
      "merged (340, 256) into a new token 423\n",
      "merged (267, 99) into a new token 424\n",
      "merged (290, 265) into a new token 425\n",
      "merged (333, 98) into a new token 426\n",
      "merged (108, 121) into a new token 427\n",
      "merged (105, 109) into a new token 428\n",
      "merged (100, 262) into a new token 429\n",
      "merged (353, 256) into a new token 430\n",
      "merged (105, 114) into a new token 431\n",
      "merged (103, 402) into a new token 432\n",
      "merged (288, 32) into a new token 433\n",
      "merged (99, 97) into a new token 434\n",
      "merged (108, 265) into a new token 435\n",
      "merged (115, 104) into a new token 436\n",
      "merged (259, 297) into a new token 437\n",
      "merged (97, 103) into a new token 438\n",
      "merged (339, 110) into a new token 439\n",
      "merged (316, 32) into a new token 440\n",
      "merged (104, 32) into a new token 441\n",
      "merged (108, 269) into a new token 442\n",
      "merged (264, 32) into a new token 443\n",
      "merged (98, 274) into a new token 444\n",
      "merged (279, 399) into a new token 445\n",
      "merged (257, 111) into a new token 446\n",
      "merged (112, 112) into a new token 447\n",
      "merged (115, 275) into a new token 448\n",
      "merged (108, 111) into a new token 449\n",
      "merged (321, 283) into a new token 450\n",
      "merged (258, 270) into a new token 451\n",
      "merged (377, 355) into a new token 452\n",
      "merged (258, 354) into a new token 453\n",
      "merged (118, 256) into a new token 454\n",
      "merged (272, 100) into a new token 455\n",
      "merged (313, 273) into a new token 456\n",
      "merged (298, 256) into a new token 457\n",
      "merged (349, 270) into a new token 458\n",
      "merged (262, 256) into a new token 459\n",
      "merged (45, 32) into a new token 460\n",
      "merged (415, 368) into a new token 461\n",
      "merged (281, 116) into a new token 462\n",
      "merged (417, 362) into a new token 463\n",
      "merged (421, 315) into a new token 464\n",
      "merged (41, 268) into a new token 465\n",
      "merged (115, 121) into a new token 466\n",
      "merged (258, 256) into a new token 467\n",
      "merged (299, 347) into a new token 468\n",
      "merged (330, 262) into a new token 469\n",
      "merged (260, 101) into a new token 470\n",
      "merged (352, 261) into a new token 471\n",
      "merged (371, 354) into a new token 472\n",
      "merged (115, 345) into a new token 473\n",
      "merged (256, 297) into a new token 474\n",
      "merged (117, 100) into a new token 475\n",
      "merged (346, 107) into a new token 476\n",
      "merged (299, 261) into a new token 477\n",
      "merged (115, 280) into a new token 478\n",
      "merged (105, 122) into a new token 479\n",
      "merged (97, 294) into a new token 480\n",
      "merged (269, 423) into a new token 481\n",
      "merged (289, 435) into a new token 482\n",
      "merged (111, 108) into a new token 483\n",
      "merged (101, 288) into a new token 484\n",
      "merged (279, 461) into a new token 485\n",
      "merged (452, 425) into a new token 486\n",
      "merged (113, 117) into a new token 487\n",
      "merged (119, 32) into a new token 488\n",
      "merged (275, 407) into a new token 489\n",
      "merged (105, 102) into a new token 490\n",
      "merged (281, 310) into a new token 491\n",
      "merged (390, 389) into a new token 492\n",
      "merged (112, 266) into a new token 493\n",
      "merged (304, 309) into a new token 494\n",
      "merged (258, 376) into a new token 495\n",
      "merged (110, 405) into a new token 496\n",
      "merged (406, 380) into a new token 497\n",
      "merged (263, 103) into a new token 498\n",
      "merged (110, 319) into a new token 499\n"
     ]
    }
   ],
   "source": [
    "def createVocab(size, tokens):\n",
    "    new_tokens = list(tokens)\n",
    "    current_size = 256\n",
    "    num_merges = size - current_size\n",
    "    print(num_merges)\n",
    "    merges = {}\n",
    "    \n",
    "    for i in range(num_merges):\n",
    "        stats = getCommonPair(new_tokens)\n",
    "        new_id = current_size + i\n",
    "        common = max(stats, key=stats.get)\n",
    "        new_tokens = merge(new_tokens, common, new_id)\n",
    "        print(\"merged\", str(common), \"into a new token\", str(new_id))\n",
    "        merges[common] = new_id\n",
    "\n",
    "    return (new_tokens, merges)\n",
    "\n",
    "new_tokens, merges = createVocab(500, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b14d524-315b-4458-99bc-bf2baf63e70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens length: 38425\n",
      "New tokens length: 17153\n",
      "Compression ratio: 2.24X\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens length:\", len(tokens))\n",
    "print(\"New tokens length:\", len(new_tokens))\n",
    "print(f\"Compression ratio: {len(tokens) / len(new_tokens):.2f}X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85b47904-b922-4803-9dd3-6b0147f1b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifical from parill inputnumstructangnow\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "for idx in range(256):\n",
    "    vocab[idx] = bytes([idx])\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "    \n",
    "def decode(ids):\n",
    "    # s = \"\"\n",
    "    # for idx in ids:\n",
    "    #     byts = vocab[idx]\n",
    "    #     for byte in byts:\n",
    "    #         s = s + chr(byte)\n",
    "    # return s\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return textmpo\n",
    "\n",
    "print(decode([490, 491, 492, 493, 494, 495, 496, 497, 498, 499]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32ef3804-452d-499f-9f24-f387626952dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n"
     ]
    }
   ],
   "source": [
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    while len(tokens) >= 2:\n",
    "        stats = getCommonPair(tokens)\n",
    "        pair = min(stats, key= lambda p: merges.get(p, float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break # nothing else can be merged\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "print(encode(\"ifical from parill inputnumstructangnow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40e00313-baa9-497b-ada0-2fb7853f0dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this working?\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"Is this working?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1017e07-2577-4108-831c-1575534afcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text2 = decode(encode(text))\n",
    "print(text2 == text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3eb4648-7906-444b-8f70-44250e6d90b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "valtext = \"Project Jupyter’s tools are available for installation via the Python Package Index, the leading repository of software created for the Python programming language. This page uses instructions with pip, the recommended installation tool for Python. If you require environment management as opposed to just installation, look into conda, mamba, pipenv, and Homebrew.\"\n",
    "valtext2 = decode(encode(valtext))\n",
    "print(valtext2 == valtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c3f10-e458-435c-8016-33501635b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "gpt2pat = regex.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\", regex.IGNORECASE)\n",
    "\n",
    "print(regex.findall(gpt2pat, \"Hello world HOW'S how's\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b574c6e7-9035-4a0d-89de-7cec7483f493",
   "metadata": {},
   "source": [
    "# Special Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2f742-2112-40c4-9c44-77e7993b8b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
